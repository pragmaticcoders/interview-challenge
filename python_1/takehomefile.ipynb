{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer Take-Home Exercise\n",
    "\n",
    "## Overview\n",
    "Your task is to design an end-to-end data pipeline. The main assumption is that data may appear once a day in the form of a ZIP file available on a publicly accessible S3 bucket. These data will appear on random days during the month, and our task is to download this data whenever it becomes available. Information that the data is available can be found on the data provider's website or through a publicly accessible API. Size of the data will increase, therefore please assume it may grow to files of hundreds of GBs while compressed. \n",
    "## Task Breakdown\n",
    "\n",
    "### 1. Pipeline Design\n",
    "- **Objective**: Develop a conceptual architecture for the data pipeline.\n",
    "- **Requirements**: No coding required. Prepare a presentation (format is flexible, no need for PowerPoint) illustrating the proposed architecture, including your choice of AWS services and frameworks.\n",
    "\n",
    "### 2. Data Processing\n",
    "- **Objective**: Write code to transform the provided source data.\n",
    "- **Requirements**: Use Python 3.9, Spark 3.3, or newer. Prepare a Jupyter Notebook to explain your approach and thought process.\n",
    "- **Deliverables**: Transform the source data as per provided specifications.\n",
    "\n",
    "### 3. Presentation\n",
    "- **Procedure**: Submit your solutions for the first two parts. We will review them and arrange a meeting to discuss your approach and the solutions in detail.\n",
    "## Detailed Instructions for Data Processing\n",
    "\n",
    "### Task: Transforming Data\n",
    "You will find `data.csv` in the files folder. Your task involves three key steps, each focusing on manipulating specific field values:\n",
    "\n",
    "1. **String Cleaning**: The 'bio' field contains inconsistently formatted text. Standardize these values to a space-delimited string.\n",
    "2. **Code Swap**: Use the `state_abbreviations` CSV from the files folder. Replace state abbreviations in the 'state' field of `data.csv` with the full state names from this supplementary file.\n",
    "3. **Date Offset**: The 'start_date' field has varied date formats. Create a new field, 'start_date_description', to filter out invalid dates. Normalize valid dates to ISO 8601 format (YYYY-MM-DD).\n",
    "\n",
    "**Final Output**: Your script should process `data.csv` and produce an `enriched.csv` and `enriched.snappy.parquet` file as per the above requirements. Address any additional data quality issues you encounter.\n",
    "\n",
    "### Assessment Criteria\n",
    "Our aim is to see your best work. We appreciate clean, DRY (Don't Repeat Yourself) code that is well-documented. Our assessment will focus on:\n",
    "\n",
    "1. Problem-solving effectiveness.\n",
    "2. Clarity and logical structuring of your solution.\n",
    "3. Quality of documentation and code commenting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
